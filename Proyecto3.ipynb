{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 3 Visión por Computadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findAndDescribeFeatures(image, opt=\"ORB\"):\n",
    "    \"\"\"find and describe features of @image,\n",
    "        if opt='SURF', SURF algorithm is used.\n",
    "        if opt='SIFT', SIFT algorithm is used.\n",
    "        if opt='ORB', ORB algorithm is used.\n",
    "        @Return keypoints and features of img\"\"\"\n",
    "    # Getting gray image\n",
    "    grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if opt == \"SURF\":\n",
    "        md = cv2.xfeatures2d.SURF_create()\n",
    "    if opt == \"ORB\":\n",
    "        md = cv2.ORB_create(nfeatures=3000)\n",
    "    if opt == \"SIFT\":\n",
    "        md = cv2.xfeatures2d.SIFT_create()\n",
    "    # Find interest points and Computing features.\n",
    "    keypoints, features = md.detectAndCompute(grayImage, None)\n",
    "    # Converting keypoints to numbers.\n",
    "    # keypoints = np.float32(keypoints)\n",
    "    features = np.float32(features)\n",
    "    return keypoints, features\n",
    "\n",
    "\n",
    "def matchFeatures(featuresA, featuresB, ratio=0.75, opt=\"FB\"):\n",
    "    \"\"\"matching features beetween 2 @features.\n",
    "         If opt='FB', FlannBased algorithm is used.\n",
    "         If opt='BF', BruteForce algorithm is used.\n",
    "         @ratio is the Lowe's ratio test.\n",
    "         @return matches\"\"\"\n",
    "    if opt == \"BF\":\n",
    "        featureMatcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    if opt == \"FB\":\n",
    "        # featureMatcher = cv2.DescriptorMatcher_create(\"FlannBased\")\n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        featureMatcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # performs k-NN matching between the two feature vector sets using k=2\n",
    "    # (indicating the top two matches for each feature vector are returned).\n",
    "    matches = featureMatcher.knnMatch(featuresA, featuresB, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append(m)\n",
    "    if len(good) > 4:\n",
    "        return good\n",
    "    raise Exception(\"Not enought matches\")\n",
    "\n",
    "\n",
    "def generateHomography(src_img, dst_img, ransacRep=5.0):\n",
    "    \"\"\"@Return Homography matrix, @param src_img is the image which is warped by homography,\n",
    "        @param dst_img is the image which is choosing as pivot, @param ratio is the David Lowe’s ratio,\n",
    "        @param ransacRep is the maximum pixel “wiggle room” allowed by the RANSAC algorithm\n",
    "        \"\"\"\n",
    "\n",
    "    src_kp, src_features = findAndDescribeFeatures(src_img)\n",
    "    dst_kp, dst_features = findAndDescribeFeatures(dst_img)\n",
    "\n",
    "    good = matchFeatures(src_features, dst_features)\n",
    "\n",
    "    src_points = np.float32([src_kp[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_points = np.float32([dst_kp[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    H, mask = cv2.findHomography(src_points, dst_points, cv2.RANSAC, ransacRep)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    return H, matchesMask\n",
    "\n",
    "\n",
    "def drawKeypoints(img, kp):\n",
    "    img1 = img\n",
    "    cv2.drawKeypoints(img, kp, img1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return img1\n",
    "\n",
    "\n",
    "def drawMatches(src_img, src_kp, dst_img, dst_kp, matches, matchesMask):\n",
    "    draw_params = dict(\n",
    "        matchColor=(0, 255, 0),  # draw matches in green color\n",
    "        singlePointColor=None,\n",
    "        matchesMask=matchesMask[:100],  # draw only inliers\n",
    "        flags=2,\n",
    "    )\n",
    "    return cv2.drawMatches(\n",
    "        src_img, src_kp, dst_img, dst_kp, matches[:100], None, **draw_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blendingMask(height, width, barrier, smoothing_window, left_biased=True):\n",
    "    assert barrier < width\n",
    "    mask = np.zeros((height, width))\n",
    "\n",
    "    offset = int(smoothing_window / 2)\n",
    "    try:\n",
    "        if left_biased:\n",
    "            mask[:, barrier - offset : barrier + offset + 1] = np.tile(\n",
    "                np.linspace(1, 0, 2 * offset + 1).T, (height, 1)\n",
    "            )\n",
    "            mask[:, : barrier - offset] = 1\n",
    "        else:\n",
    "            mask[:, barrier - offset : barrier + offset + 1] = np.tile(\n",
    "                np.linspace(0, 1, 2 * offset + 1).T, (height, 1)\n",
    "            )\n",
    "            mask[:, barrier + offset :] = 1\n",
    "    except BaseException:\n",
    "        if left_biased:\n",
    "            mask[:, barrier - offset : barrier + offset + 1] = np.tile(\n",
    "                np.linspace(1, 0, 2 * offset).T, (height, 1)\n",
    "            )\n",
    "            mask[:, : barrier - offset] = 1\n",
    "        else:\n",
    "            mask[:, barrier - offset : barrier + offset + 1] = np.tile(\n",
    "                np.linspace(0, 1, 2 * offset).T, (height, 1)\n",
    "            )\n",
    "            mask[:, barrier + offset :] = 1\n",
    "\n",
    "    return cv2.merge([mask, mask, mask])\n",
    "\n",
    "\n",
    "def panoramaBlending(dst_img_rz, src_img_warped, width_dst, side, showstep=False):\n",
    "    \"\"\"Given two aligned images @dst_img and @src_img_warped, and the @width_dst is width of dst_img\n",
    "    before resize, that indicates where there is the discontinuity between the images,\n",
    "    this function produce a smoothed transient in the overlapping.\n",
    "    @smoothing_window is a parameter that determines the width of the transient\n",
    "    left_biased is a flag that determines whether it is masked the left image,\n",
    "    or the right one\"\"\"\n",
    "\n",
    "    h, w, _ = dst_img_rz.shape\n",
    "    smoothing_window = int(width_dst / 8)\n",
    "    barrier = width_dst - int(smoothing_window / 2)\n",
    "    mask1 = blendingMask(\n",
    "        h, w, barrier, smoothing_window=smoothing_window, left_biased=True\n",
    "    )\n",
    "    mask2 = blendingMask(\n",
    "        h, w, barrier, smoothing_window=smoothing_window, left_biased=False\n",
    "    )\n",
    "\n",
    "    if showstep:\n",
    "        nonblend = src_img_warped + dst_img_rz\n",
    "    else:\n",
    "        nonblend = None\n",
    "        leftside = None\n",
    "        rightside = None\n",
    "\n",
    "    if side == \"left\":\n",
    "        dst_img_rz = cv2.flip(dst_img_rz, 1)\n",
    "        src_img_warped = cv2.flip(src_img_warped, 1)\n",
    "        dst_img_rz = dst_img_rz * mask1\n",
    "        src_img_warped = src_img_warped * mask2\n",
    "        pano = src_img_warped + dst_img_rz\n",
    "        pano = cv2.flip(pano, 1)\n",
    "        if showstep:\n",
    "            leftside = cv2.flip(src_img_warped, 1)\n",
    "            rightside = cv2.flip(dst_img_rz, 1)\n",
    "    else:\n",
    "        dst_img_rz = dst_img_rz * mask1\n",
    "        src_img_warped = src_img_warped * mask2\n",
    "        pano = src_img_warped + dst_img_rz\n",
    "        if showstep:\n",
    "            leftside = dst_img_rz\n",
    "            rightside = src_img_warped\n",
    "\n",
    "    return pano, nonblend, leftside, rightside\n",
    "\n",
    "\n",
    "def warpTwoImages(src_img, dst_img, showstep=False):\n",
    "\n",
    "    # generate Homography matrix\n",
    "    H, _ = generateHomography(src_img, dst_img)\n",
    "\n",
    "    # get height and width of two images\n",
    "    height_src, width_src = src_img.shape[:2]\n",
    "    height_dst, width_dst = dst_img.shape[:2]\n",
    "\n",
    "    # extract conners of two images: top-left, bottom-left, bottom-right, top-right\n",
    "    pts1 = np.float32(\n",
    "        [[0, 0], [0, height_src], [width_src, height_src], [width_src, 0]]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32(\n",
    "        [[0, 0], [0, height_dst], [width_dst, height_dst], [width_dst, 0]]\n",
    "    ).reshape(-1, 1, 2)\n",
    "\n",
    "    try:\n",
    "        # aply homography to conners of src_img\n",
    "        pts1_ = cv2.perspectiveTransform(pts1, H)\n",
    "        pts = np.concatenate((pts1_, pts2), axis=0)\n",
    "\n",
    "        # find max min of x,y coordinate\n",
    "        [xmin, ymin] = np.int64(pts.min(axis=0).ravel() - 0.5)\n",
    "        [_, ymax] = np.int64(pts.max(axis=0).ravel() + 0.5)\n",
    "        t = [-xmin, -ymin]\n",
    "\n",
    "        # top left point of image which apply homography matrix, which has x coordinate < 0, has side=left\n",
    "        # otherwise side=right\n",
    "        # source image is merged to the left side or right side of destination image\n",
    "        if pts[0][0][0] < 0:\n",
    "            side = \"left\"\n",
    "            width_pano = width_dst + t[0]\n",
    "        else:\n",
    "            width_pano = int(pts1_[3][0][0])\n",
    "            side = \"right\"\n",
    "        height_pano = ymax - ymin\n",
    "\n",
    "        # Translation\n",
    "        # https://stackoverflow.com/a/20355545\n",
    "        Ht = np.array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]])\n",
    "        src_img_warped = cv2.warpPerspective(\n",
    "            src_img, Ht.dot(H), (width_pano, height_pano)\n",
    "        )\n",
    "        # generating size of dst_img_rz which has the same size as src_img_warped\n",
    "        dst_img_rz = np.zeros((height_pano, width_pano, 3))\n",
    "        if side == \"left\":\n",
    "            dst_img_rz[t[1] : height_src + t[1], t[0] : width_dst + t[0]] = dst_img\n",
    "        else:\n",
    "            dst_img_rz[t[1] : height_src + t[1], :width_dst] = dst_img\n",
    "\n",
    "        # blending panorama\n",
    "        pano, nonblend, leftside, rightside = panoramaBlending(\n",
    "            dst_img_rz, src_img_warped, width_dst, side, showstep=showstep\n",
    "        )\n",
    "\n",
    "        # croping black region\n",
    "        pano = crop(pano, height_dst, pts)\n",
    "        return pano, nonblend, leftside, rightside\n",
    "    except BaseException:\n",
    "        raise Exception(\"Please try again with another image set!\")\n",
    "\n",
    "\n",
    "def multiStitching(list_images):\n",
    "    \"\"\"assume that the list_images was supplied in left-to-right order, choose middle image then\n",
    "    divide the array into 2 sub-arrays, left-array and right-array. Stiching middle image with each\n",
    "    image in 2 sub-arrays. @param list_images is The list which containing images, @param smoothing_window is\n",
    "    the value of smoothy side after stitched, @param output is the folder which containing stitched image\n",
    "    \"\"\"\n",
    "    n = int(len(list_images) / 2 + 0.5)\n",
    "    left = list_images[:n]\n",
    "    right = list_images[n - 1 :]\n",
    "    right.reverse()\n",
    "    while len(left) > 1:\n",
    "        dst_img = left.pop()\n",
    "        src_img = left.pop()\n",
    "        left_pano, _, _, _ = warpTwoImages(src_img, dst_img)\n",
    "        left_pano = left_pano.astype(\"uint8\")\n",
    "        left.append(left_pano)\n",
    "\n",
    "    while len(right) > 1:\n",
    "        dst_img = right.pop()\n",
    "        src_img = right.pop()\n",
    "        right_pano, _, _, _ = warpTwoImages(src_img, dst_img)\n",
    "        right_pano = right_pano.astype(\"uint8\")\n",
    "        right.append(right_pano)\n",
    "\n",
    "    # if width_right_pano > width_left_pano, Select right_pano as destination. Otherwise is left_pano\n",
    "    if right_pano.shape[1] >= left_pano.shape[1]:\n",
    "        fullpano, _, _, _ = warpTwoImages(left_pano, right_pano)\n",
    "    else:\n",
    "        fullpano, _, _, _ = warpTwoImages(right_pano, left_pano)\n",
    "    return fullpano\n",
    "\n",
    "\n",
    "def crop(panorama, h_dst, conners):\n",
    "    \"\"\"crop panorama based on destination.\n",
    "    @param panorama is the panorama\n",
    "    @param h_dst is the hight of destination image\n",
    "    @param conner is the tuple which containing 4 conners of warped image and\n",
    "    4 conners of destination image\"\"\"\n",
    "    # find max min of x,y coordinate\n",
    "    [xmin, ymin] = np.int32(conners.min(axis=0).ravel() - 0.5)\n",
    "    t = [-xmin, -ymin]\n",
    "    conners = conners.astype(int)\n",
    "\n",
    "    # conners[0][0][0] is the X coordinate of top-left point of warped image\n",
    "    # If it has value<0, warp image is merged to the left side of destination image\n",
    "    # otherwise is merged to the right side of destination image\n",
    "    if conners[0][0][0] < 0:\n",
    "        n = abs(-conners[1][0][0] + conners[0][0][0])\n",
    "        panorama = panorama[t[1] : h_dst + t[1], n:, :]\n",
    "    else:\n",
    "        if conners[2][0][0] < conners[3][0][0]:\n",
    "            panorama = panorama[t[1] : h_dst + t[1], 0 : conners[2][0][0], :]\n",
    "        else:\n",
    "            panorama = panorama[t[1] : h_dst + t[1], 0 : conners[3][0][0], :]\n",
    "    return panorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def loadImages(path, resize):\n",
    "    \"\"\"Load Images from path to array, @param path is the folder which containing images, @param resize is True\n",
    "    if image is halved in size, otherwise is False\"\"\"\n",
    "    image_path = sorted(list(paths.list_images(path)))\n",
    "    list_image = []\n",
    "    for _, j in enumerate(image_path):\n",
    "        image = cv2.imread(j)\n",
    "        if resize == 1:\n",
    "            image = cv2.resize(\n",
    "                image, (int(image.shape[1] / 4), int(image.shape[0] / 4))\n",
    "            )\n",
    "        list_image.append(image)\n",
    "    return list_image\n",
    "\n",
    "\n",
    "def trim(frame):\n",
    "    \"\"\"crop frame \"\"\"\n",
    "    # crop top\n",
    "    if not np.sum(frame[0]):\n",
    "        return trim(frame[1:])\n",
    "    # crop bottom\n",
    "    if not np.sum(frame[-1]):\n",
    "        return trim(frame[:-2])\n",
    "    # crop left\n",
    "    if not np.sum(frame[:, 0]):\n",
    "        return trim(frame[:, 1:])\n",
    "    # crop right\n",
    "    if not np.sum(frame[:, -1]):\n",
    "        return trim(frame[:, :-2])\n",
    "    return frame\n",
    "\n",
    "\n",
    "def padding(img, top, bottom, left, right):\n",
    "    \"\"\"add padding to img\"\"\"\n",
    "    border = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top=top,\n",
    "        bottom=bottom,\n",
    "        left=left,\n",
    "        right=right,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "    )\n",
    "    return border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing....\n",
      "247\n",
      "158\n",
      "184\n",
      "168\n",
      "81\n",
      "685\n",
      "Complete!\n",
      "Execution time:  3.6753403000002436\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import stitch\n",
    "import utils\n",
    "import timeit\n",
    "import os\n",
    "\n",
    "input = './prueba2'\n",
    "output = './output'\n",
    "resize = 2\n",
    "\n",
    "# caculate execution time\n",
    "print(\"Processing....\")\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# load images\n",
    "list_images = utils.loadImages(input, resize)\n",
    "\n",
    "# create panorama, default using ORB with nfeatures=3000, u can change to SIFT, SURF in features.py or add some argument\n",
    "panorama = stitch.multiStitching(list_images)\n",
    "\n",
    "# save\n",
    "if output:\n",
    "    cv2.imwrite(os.path.join(output, \"result.jpg\"), panorama)\n",
    "else:\n",
    "    cv2.imwrite(\"result.jpg\", panorama)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Complete!\")\n",
    "print(\"Execution time: \", stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
